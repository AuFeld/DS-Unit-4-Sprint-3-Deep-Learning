{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DS_431_Key_Terms.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPknqV29bNVY///TU9UHjn0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AuFeld/DS-Unit-4-Sprint-3-Deep-Learning/blob/master/module1-rnn-and-lstm/DS_431_Key_Terms.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OR0IONhF3ZZK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Key Terms and Concepts"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZCaQxWH347AD",
        "colab_type": "text"
      },
      "source": [
        "# What is a Recurrent Neural Network (RNN) ?\n",
        "\n",
        "RNN is a generalization of feedforward neural network that has an internal memory. RNN is recurrent in nature as it performs the same function for every input of data while the output of the current input depends on the past one computation. After producing the output, it is copied and sent back into the recurrent network. For making a decision, it considers the current input and the output that it has learned from the previous input.\n",
        "\n",
        "Unlike feedforward neural networks, RNNs can use their internal state (memory) to process sequences of inputs. This makes them applicable to tasks such as unsegmented, connected handwriting recognition or speech recognition. In other neural networks, all the inputs are independent of each other. But in RNN, all the inputs are related to each other.\n",
        "\n",
        "## Advantages of RNN: \n",
        "\n",
        "1. RNN can model sequence of data so that each sample can be assumed to be dependent on previous ones. \n",
        "\n",
        "2. RNN are even used with convolutional layers to extend the effective pixel neighborhood. \n",
        "\n",
        "## Disadvantages of RNN: \n",
        "\n",
        "1. Gradient vanishing and exploding problems. \n",
        "\n",
        "2. Training a RNN is a very difficult task. \n",
        "\n",
        "3. It cannot process very long sequences if using Tanh or Relu as an activation function.\n",
        "\n",
        "\n",
        "# What is a long short term memory (LSTM) ?\n",
        "\n",
        "Long Short-Term Memory networks are a modified version of a RNN, which makes it easier to remember past data in memory. The vanishing gradient problem of RNN is resolved here. LSTM is well-suited to classify, process, and predict time series given lags of unknown duration. It trains the model by using backpropagation. \n",
        "\n",
        "In a LSTM network, three gates are present: \n",
        "\n",
        "1. Input gate: discover which value from input should be used to modify the memory. Sigmoid function decides which values to let through from 0 to 1. Tanh activation function gives weightage to the values which are passed deciding their level of importance ranging from -1 to 1. \n",
        "\n",
        "2. Forget Gate: discovers what details to be discarded from the block. It is decided by the sigmoid function. \n",
        "\n",
        "3. Output Gate: the input and the memory of the block is used to decide the output. Sigmoid function decides which values to let through from 0 to 1. Tanh function gives weightage to the values which are passed deciding their level of importance ranging from -1 to 1 and multiplied with output of Sigmoid."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pn7MhdU4-nAb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}